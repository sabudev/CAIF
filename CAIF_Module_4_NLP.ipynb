{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "CAIF Module 4 - NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabudev/CAIF/blob/main/CAIF_Module_4_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUcYmWStoe6r"
      },
      "source": [
        "# Wordclouds\n",
        "\n",
        "Wordclouds are excellent ways to summarize textual information like reviews, customer feedback, documents etc. The first part of this excercise focuses on creating a word cloud from the text descriptions in the wine dataset that you have seen earlier in Part 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riY1Eyuroe6s"
      },
      "source": [
        "!pip install wordcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY2_qhuXoe6s"
      },
      "source": [
        "# Start with loading all necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from nltk import FreqDist\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enB5dFbRQRP0"
      },
      "source": [
        "**Load the Data files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cSb71oLOsu_"
      },
      "source": [
        "! git clone https://github.com/vibsabhishek/EP290.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etfksvnooe6s"
      },
      "source": [
        "# Load in the dataframe\n",
        "df = pd.read_csv(\"EP290/winemag-data-2500.csv\", index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXqh0JvVoe6u"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7_vI_lpzq2b"
      },
      "source": [
        "print(df.description[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ug0zRHaoe6t"
      },
      "source": [
        "# Start with one review:\n",
        "text = df.description[0]\n",
        "\n",
        "# Create and generate a word cloud image:\n",
        "wordcloud = WordCloud().generate(text)\n",
        "\n",
        "# Display the generated image:\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XW-A1Rqoe6t"
      },
      "source": [
        "print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DNGx-booe6u"
      },
      "source": [
        "# Save the image in the img folder:\n",
        "wordcloud.to_file(\"first_review.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88aXBP8Poe6u"
      },
      "source": [
        "#combine all the descriptions into one big text variable\n",
        "text = \" \".join(description for description in df.description)\n",
        "print (\"There are {} words in the combination of all review.\".format(len(text)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0mjME-Voe6v"
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tokens = tokenizer.tokenize(text)\n",
        "freq = FreqDist(tokens)\n",
        "freq.plot(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWzp4CzG3Ek4"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "freq.plot(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltdr0knVoe6v"
      },
      "source": [
        "## Q1. Plot the distribution of the entire corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZzoSXVO1EJN"
      },
      "source": [
        "freq.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbPx1EkXoe6w"
      },
      "source": [
        "## Zipf's law\n",
        "\n",
        "The distribution of text follows a Zipf's or scale-free distribution. This is quite characteristic of any naturally occuring text corpus, irrespective of language. \n",
        "\n",
        "## Q2. What is the most commonly occuring word?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQQrsBk6oe6w"
      },
      "source": [
        "### Stopwords\n",
        "\n",
        "Some words like the, and etc. even though commonly occuring do not add a lot of value as they are not unique to the context. In addition, we might wish to remove commonly occuring words for a specific context, e.g. \"wine\", and \"drink\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsMopeFfoe6w"
      },
      "source": [
        "# Create stopword list:\n",
        "stopwords = set(STOPWORDS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWvPszusoe6w"
      },
      "source": [
        "## Q3. Add a set of stopwords specific to the wine descriptions and generate another wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD5skiIOoe6w"
      },
      "source": [
        "stopwords.update([\"wine\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysnaF2dQoe6x"
      },
      "source": [
        "# Generate a word cloud image\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", width=1000, height=800).generate(text)\n",
        "\n",
        "# Display the generated image:\n",
        "# the matplotlib way:\n",
        "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGpuIgG53nza"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMGaSPIcoe6x"
      },
      "source": [
        "## Apply an image mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEZ7HFiAoe6x"
      },
      "source": [
        "wine_mask = np.array(Image.open(\"EP290/winemask.png\"))\n",
        "wine_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsfVSTsIoe6x"
      },
      "source": [
        "def transform_format(val):\n",
        "    if val == 0:\n",
        "        return 255\n",
        "    else:\n",
        "        return val\n",
        "\n",
        "# Transform your mask into a new one that will work with the function:\n",
        "transformed_wine_mask = np.ndarray((wine_mask.shape[0],wine_mask.shape[1]), np.int32)\n",
        "\n",
        "for i in range(len(wine_mask)):\n",
        "    transformed_wine_mask[i] = list(map(transform_format, wine_mask[i]))\n",
        "\n",
        "# Check the expected result of your mask\n",
        "transformed_wine_mask\n",
        "\n",
        "# Create a word cloud image\n",
        "wc = WordCloud(background_color=\"white\", mask=transformed_wine_mask,\n",
        "               stopwords=stopwords, contour_width=1, contour_color='firebrick', width=1000, height=800)\n",
        "\n",
        "# Generate a wordcloud\n",
        "wc.generate(text)\n",
        "\n",
        "# store to file\n",
        "wc.to_file(\"wine.png\")\n",
        "\n",
        "# show\n",
        "plt.figure(figsize=[10,10])\n",
        "plt.imshow(wc)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVu9fl8vfq39"
      },
      "source": [
        "## Q4. Create the world cloud for the abstracts in COVID data (in file: EP290/covid19_small.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfy_lSDOFgSO"
      },
      "source": [
        "df = pd.read_csv(\"EP290/covid19_small.csv\", index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USR7e1znFpuk"
      },
      "source": [
        "df.abstract[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdR0JFD5oe6y"
      },
      "source": [
        "\n",
        "# Sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncesuhQvoe6y"
      },
      "source": [
        "Here we will try to find the sentiment of various text, a very common application of NLP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siFNCyoOoe6y"
      },
      "source": [
        "## Import packages\n",
        "Make sure you installed ***sklearn***, ***matplotlib*** and ***numpy*** if you use your local machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI0hUnLJKPKS"
      },
      "source": [
        "!pip install -U textblob\n",
        "!pip install vaderSentiment\n",
        "!python -m textblob.download_corpora"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlzuxK0_oe6y"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from os import path\n",
        "import seaborn as sns\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.metrics import confusion_matrix, precision_score, precision_recall_curve, recall_score, f1_score, accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB0z8tpkJ_QP"
      },
      "source": [
        "##**Sentiment Analysis using VADER**\n",
        "\n",
        "*   For compound > 0.05 - Positive\n",
        "*   For compound < -0.05 - Negative\n",
        "*   else Neutral\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYITCOeFJ9c3"
      },
      "source": [
        "vader = SentimentIntensityAnalyzer()\n",
        "text_sentiment = vader.polarity_scores(\"VADER is amazingly simple to use. What great fun!\")\n",
        "print(text_sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvyjptyYKow_"
      },
      "source": [
        "text_sentiment = vader.polarity_scores(\"VADER is terrible to use. What a shame!\")\n",
        "print(text_sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btr7W9J06BGr"
      },
      "source": [
        "text_sentiment = vader.polarity_scores(\"He is not going to hate that.\")\n",
        "print(text_sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7E761dfWOjx"
      },
      "source": [
        "## **Sentiment analysis on IMDB review dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X275PN0QVGwG"
      },
      "source": [
        "df = pd.read_excel(\"EP290/IMDB_Dataset_small.xls\", header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6aYZJL5VV3j"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cbJuV3L7Ch7"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mf6ArKuict8"
      },
      "source": [
        "## Q5. Show the distribution of words containted in the IMDB reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9LWmH0rMtHG"
      },
      "source": [
        "#some helper function to measure sentiment\n",
        "def detect_vader_pos(text):\n",
        "    return vader.polarity_scores(text)['pos']\n",
        "\n",
        "def detect_vader_neg(text):\n",
        "    return vader.polarity_scores(text)['neg']\n",
        "\n",
        "def detect_vader_comp(text):\n",
        "    return vader.polarity_scores(text)['compound']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz4Qlz2lVe2P"
      },
      "source": [
        "print(\"Review:\", df.review[0],\"\\n Sentiment:\", df.sentiment[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_I5X_8-Wu9H"
      },
      "source": [
        "###Compute Sentiment for the entire dataset using VADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irJT51_mV6HZ"
      },
      "source": [
        "vader = SentimentIntensityAnalyzer()\n",
        "df['vader_pos'] = df.review.apply(detect_vader_pos)\n",
        "df['vader_neg'] = df.review.apply(detect_vader_neg)\n",
        "df['vader_comp'] = df.review.apply(detect_vader_comp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFqKvoeXW2gR"
      },
      "source": [
        "#Visualize the results\n",
        "plt.figure(figsize=[4,4])\n",
        "\n",
        "ax = sns.violinplot(x=\"sentiment\", y=\"vader_comp\", data=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqijOfqxXTGY"
      },
      "source": [
        "plt.figure(figsize=[4,4])\n",
        "ax = sns.violinplot(x=\"sentiment\", y=\"vader_pos\", data=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUb0wUh4XblX"
      },
      "source": [
        "plt.figure(figsize=[4,4])\n",
        "ax = sns.violinplot(x=\"sentiment\", y=\"vader_neg\", data=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM7DoGrdXtwt"
      },
      "source": [
        "v_pred = np.where(df['vader_comp'] > 0.0, \"positive\", \"negative\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lq7fugqXy5k"
      },
      "source": [
        "print(\"Confusion Matrix:\\n\", confusion_matrix(df.sentiment, v_pred))\n",
        "print(\"F1 score:\", f1_score(df.sentiment, v_pred, average='micro'))\n",
        "print(\"Accuracy score:\", accuracy_score(df.sentiment, v_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpaPLLAsiom0"
      },
      "source": [
        "## **Creating our own classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mipFS3jEoe62"
      },
      "source": [
        "## Count Vectorizer\n",
        "- run count vectorizer on it\n",
        "- plot histograms of counts etc.\n",
        "- vary the parameters of Cvectorizer, show how histograms change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcP-PIT7oe62"
      },
      "source": [
        "### Split into train and test datasets\n",
        "Here, 70% of the original data are used for training models, and the rest are for test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw7hMrAzoe63"
      },
      "source": [
        "train_sample = int(len(df)*0.7)\n",
        "train = df[0:(train_sample)]\n",
        "test = df[(train_sample+1):len(df)]\n",
        "print('train data size:', len(train))\n",
        "print('test data size:', len(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyRi565toe63"
      },
      "source": [
        "### Create the vector representation of training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ55dKvxoe63"
      },
      "source": [
        "#Encode documents\n",
        "vectorizer = CountVectorizer(stop_words='english', lowercase=True, min_df=5);\n",
        "vectorizer.fit(train.review);\n",
        "\n",
        "#create vector representation\n",
        "train_vec = vectorizer.transform(train.review)\n",
        "test_vec = vectorizer.transform(test.review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmynFyyd_nAk"
      },
      "source": [
        "print(train.review[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C80ZrgSFdXPS"
      },
      "source": [
        "print(train_vec[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRK-3hh8ZLdj"
      },
      "source": [
        "lr_model = LogisticRegression(C=0.1)\n",
        "lr_model.fit(train_vec, train.sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpvbDW9PZhlQ"
      },
      "source": [
        "lr_pred = lr_model.predict(test_vec)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(test.sentiment, lr_pred))\n",
        "print(\"F1 score:\", f1_score(test.sentiment, lr_pred, average='micro'))\n",
        "print(\"Accuracy:\", accuracy_score(test.sentiment, lr_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJsZ5PySixSm"
      },
      "source": [
        "#Test an example\n",
        "reviews = [\n",
        "           \"Star Wars! This was the worst movie ever. Total waste of time.\",\n",
        "           \"Star Trek! This was the best movie ever. Totally recommended.\"\n",
        "]\n",
        "reviews_vec = vectorizer.transform(reviews)\n",
        "lr_model.predict(reviews_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVVQgFlZcqR5"
      },
      "source": [
        "## Model analysis: Examine which features are important for positive versus negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "901DoNj5Z1ms"
      },
      "source": [
        "!pip install eli5\n",
        "!pip install tabulate\n",
        "!pip install spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7qXyfRDZvvf"
      },
      "source": [
        "import eli5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGZ38d30aJ_v"
      },
      "source": [
        "eli5.show_weights(lr_model, top=20, vec=vectorizer)\n",
        "#eli5.show_prediction(lr_pred, reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx7wY_kpDTsv"
      },
      "source": [
        "eli5.show_prediction(lr_model, df.review[0], vec=vectorizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQvfofHvn3CD"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcRBPwodmbrx"
      },
      "source": [
        "!pip install pyfiglet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbEIKR2fm6CS"
      },
      "source": [
        "import pyfiglet\n",
        "  \n",
        "result = pyfiglet.figlet_format(\"That's all folks!!\\n\\n THANK YOU \\nfor be being such a sport with the Python notebooks!\")\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}